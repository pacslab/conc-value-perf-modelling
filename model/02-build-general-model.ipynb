{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Building The General Model\n",
    "\n",
    "Using the analysis created by the previous sections, we will try to build and solve the\n",
    "general model for concurrency value autoscaling.\n",
    "\n",
    "\n",
    "One important thing to note here is that the general model is evaluated every 2 seconds\n",
    "because of the inherent autoscaling evaluation period of 2 seconds in knative. As a result\n",
    "we need to convert the rates of provisioning and deprovisioning of containers from\n",
    "time rates into probability rates (from CTMC to DTCM parameters)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# imports\n",
    "\n",
    "# important libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import scipy as sp\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# for better printing of variables\n",
    "from IPython.display import display\n",
    "\n",
    "# custom imports\n",
    "from concperf import single_model, general_model\n",
    "from concperf import utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update configuration dictionary for each instance count\n",
    "def update_config(config):\n",
    "    config['arrival_rate_server'] = config['arrival_rate_total'] / config['instance_count']\n",
    "    config['base_service_time'] = config['base_service_time_ms'] / 1000\n",
    "\n",
    "model_config = {\n",
    "    # 'instance_count' should be added for each state\n",
    "    'max_conc': 10,\n",
    "    'arrival_rate_total': 5,\n",
    "    'alpha': 0.11,\n",
    "    'base_service_time_ms': 1154,\n",
    "    'max_container_count': 25,\n",
    "    'target_conc': 0.7, # assumes target utilization\n",
    "    'max_scale_up_rate': 1000, # from N to 1000*N at most\n",
    "    'max_scale_down_rate': 2, # from N to N/2 at most\n",
    "    'stable_conc_avg_count': 300, # number of times monitored concurrency will be averaged in stable mode\n",
    "    'autoscaling_interval': 2, # amount of time between autoscaling evaluations\n",
    "    'provision_rate_base': 1,\n",
    "    'deprovision_rate_base': 2,\n",
    "}\n",
    "\n",
    "single_coder = single_model.StateCoder(config=model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of states: 676\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "[(0, 0),\n (0, 1),\n (0, 2),\n (0, 3),\n (0, 4),\n (0, 5),\n (0, 6),\n (0, 7),\n (0, 8),\n (0, 9)]"
     },
     "metadata": {}
    }
   ],
   "source": [
    "general_state_coder = general_model.StateCoder(model_config)\n",
    "print('Number of states:', general_state_coder.get_state_count())\n",
    "display(general_state_coder.get_state_list()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.13533528, 0.11701964, 0.10118276, 0.08748916, 0.07564879,\n",
       "       0.06541084, 0.05655845, 0.04890409, 0.04228564, 0.27016534])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "solution = utility.get_trans_probs(10, transition_rate_base=1, max_t=model_config['autoscaling_interval'])\n",
    "solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Calculation took 1.0576083660125732 seconds for 1 instances\n",
      "Calculation took 1.1412718296051025 seconds for 2 instances\n",
      "Calculation took 0.8463587760925293 seconds for 3 instances\n",
      "Calculation took 0.6916096210479736 seconds for 4 instances\n",
      "Calculation took 0.5939676761627197 seconds for 5 instances\n",
      "Calculation took 0.5223915576934814 seconds for 6 instances\n",
      "Calculation took 0.47178196907043457 seconds for 7 instances\n",
      "Calculation took 0.46110963821411133 seconds for 8 instances\n",
      "Calculation took 0.4214193820953369 seconds for 9 instances\n",
      "Calculation took 0.4008769989013672 seconds for 10 instances\n",
      "Calculation took 0.3917732238769531 seconds for 11 instances\n",
      "Calculation took 0.3611767292022705 seconds for 12 instances\n",
      "Calculation took 0.33937644958496094 seconds for 13 instances\n",
      "Calculation took 0.33635544776916504 seconds for 14 instances\n",
      "Calculation took 0.32183218002319336 seconds for 15 instances\n",
      "Calculation took 0.30989789962768555 seconds for 16 instances\n",
      "Calculation took 0.3031005859375 seconds for 17 instances\n",
      "Calculation took 0.3004722595214844 seconds for 18 instances\n",
      "Calculation took 0.27691221237182617 seconds for 19 instances\n",
      "Calculation took 0.2833244800567627 seconds for 20 instances\n",
      "Calculation took 0.2835731506347656 seconds for 21 instances\n",
      "Calculation took 0.2717266082763672 seconds for 22 instances\n",
      "Calculation took 0.28893303871154785 seconds for 23 instances\n",
      "Calculation took 0.26012301445007324 seconds for 24 instances\n",
      "Calculation took 0.25900983810424805 seconds for 25 instances\n"
     ]
    }
   ],
   "source": [
    "# find parameters for different configuration\n",
    "\n",
    "# TODO: do something about instance count of zero\n",
    "\n",
    "for inst_count in range(1, model_config['max_container_count']+1):\n",
    "    # add instance count to config\n",
    "    model_config.update({\n",
    "        'instance_count': inst_count,\n",
    "    })\n",
    "\n",
    "    # update the config\n",
    "    update_config(model_config)\n",
    "\n",
    "    # calculate and show Q\n",
    "    Q = single_model.get_single_container_q(single_coder, config=model_config)\n",
    "    # display(pd.DataFrame(Q))\n",
    "\n",
    "    req_count_prob = utility.solve_CTMC(Q)\n",
    "    req_df = pd.DataFrame(data = {\n",
    "        'req_count': [s[0] for s in single_coder.get_state_list()],\n",
    "        'req_count_prob': req_count_prob,\n",
    "    })\n",
    "\n",
    "    # calculate measure concurrency distribution\n",
    "    avg_count = model_config['stable_conc_avg_count']\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    req_count_averaged_vals, req_count_averaged_probs = utility.get_averaged_distribution(vals=req_df['req_count'], probs=req_df['req_count_prob'], avg_count=avg_count)\n",
    "    print(f\"Calculation took {time.time() - start_time} seconds for {inst_count} instances\")\n",
    "\n",
    "    # calculate probability of different ordered instance count\n",
    "    new_order_val, new_order_prob = general_model.get_new_order_dist(req_count_averaged_vals, req_count_averaged_probs, model_config)\n",
    "\n",
    "    # plot the result\n",
    "    # plt.figure(figsize=(8,4))\n",
    "    # plt.bar(new_order_val, new_order_prob, width=1)"
   ]
  }
 ]
}