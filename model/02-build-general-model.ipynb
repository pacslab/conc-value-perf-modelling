{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Building The General Model\n",
    "\n",
    "Using the analysis created by the previous sections, we will try to build and solve the\n",
    "general model for concurrency value autoscaling.\n",
    "\n",
    "\n",
    "One important thing to note here is that the general model is evaluated every 2 seconds\n",
    "because of the inherent autoscaling evaluation period of 2 seconds in knative. As a result\n",
    "we need to convert the rates of provisioning and deprovisioning of containers from\n",
    "time rates into probability rates (from CTMC to DTCM parameters)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# imports\n",
    "\n",
    "# important libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import scipy as sp\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# for better printing of variables\n",
    "from IPython.display import display\n",
    "\n",
    "# custom imports\n",
    "from concperf import single_model, general_model\n",
    "from concperf import utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update configuration dictionary for each instance count\n",
    "def update_config(config):\n",
    "    config['arrival_rate_server'] = config['arrival_rate_total'] / config['instance_count']\n",
    "    config['base_service_time'] = config['base_service_time_ms'] / 1000\n",
    "\n",
    "model_config = {\n",
    "    # 'instance_count' should be added for each state\n",
    "    'max_conc': 10,\n",
    "    'arrival_rate_total': 5,\n",
    "    'alpha': 0.11,\n",
    "    'base_service_time_ms': 1154,\n",
    "    'max_container_count': 25,\n",
    "    'target_conc': 0.7, # assumes target utilization\n",
    "    'max_scale_up_rate': 1000, # from N to 1000*N at most\n",
    "    'max_scale_down_rate': 2, # from N to N/2 at most\n",
    "    'stable_conc_avg_count': 300, # number of times monitored concurrency will be averaged in stable mode\n",
    "    'autoscaling_interval': 2, # amount of time between autoscaling evaluations\n",
    "    'provision_rate_base': 1,\n",
    "    'deprovision_rate_base': 2,\n",
    "}\n",
    "\n",
    "single_coder = single_model.StateCoder(config=model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of states: 676\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "[(0, 0),\n (0, 1),\n (0, 2),\n (0, 3),\n (0, 4),\n (0, 5),\n (0, 6),\n (0, 7),\n (0, 8),\n (0, 9)]"
     },
     "metadata": {}
    }
   ],
   "source": [
    "general_state_coder = general_model.StateCoder(model_config)\n",
    "print('Number of states:', general_state_coder.get_state_count())\n",
    "display(general_state_coder.get_state_list()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.13533528, 0.11701964, 0.10118276, 0.08748916, 0.07564879,\n",
       "       0.06541084, 0.05655845, 0.04890409, 0.04228564, 0.27016534])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "probs = utility.get_trans_probs(10, transition_rate_base=1, max_t=model_config['autoscaling_interval'])\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "(array([1, 2, 3]), array([0.13533528, 0.11701964, 0.74764507]))"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "(array([3, 2, 1]), array([0.01831564, 0.01798018, 0.96370418]))"
     },
     "metadata": {}
    }
   ],
   "source": [
    "display(general_model.get_trans_probabilities(ready_count=1, ordered_count=3, config=model_config))\n",
    "display(general_model.get_trans_probabilities(ready_count=3, ordered_count=1, config=model_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "new order calculation took 0.9952239990234375 seconds for 1 instances\n",
      "new order calculation took 1.1617624759674072 seconds for 2 instances\n",
      "new order calculation took 0.9039413928985596 seconds for 3 instances\n",
      "new order calculation took 0.7111666202545166 seconds for 4 instances\n",
      "new order calculation took 0.6478042602539062 seconds for 5 instances\n",
      "new order calculation took 0.5342798233032227 seconds for 6 instances\n",
      "new order calculation took 0.4782235622406006 seconds for 7 instances\n",
      "new order calculation took 0.483762264251709 seconds for 8 instances\n",
      "new order calculation took 0.4843006134033203 seconds for 9 instances\n",
      "new order calculation took 0.3890533447265625 seconds for 10 instances\n",
      "new order calculation took 0.3898956775665283 seconds for 11 instances\n",
      "new order calculation took 0.377596378326416 seconds for 12 instances\n",
      "new order calculation took 0.34400463104248047 seconds for 13 instances\n",
      "new order calculation took 0.35578036308288574 seconds for 14 instances\n",
      "new order calculation took 0.3660426139831543 seconds for 15 instances\n",
      "new order calculation took 0.32151031494140625 seconds for 16 instances\n",
      "new order calculation took 0.32492613792419434 seconds for 17 instances\n",
      "new order calculation took 0.30060648918151855 seconds for 18 instances\n",
      "new order calculation took 0.28760266304016113 seconds for 19 instances\n",
      "new order calculation took 0.31034278869628906 seconds for 20 instances\n",
      "new order calculation took 0.2792372703552246 seconds for 21 instances\n",
      "new order calculation took 0.2880129814147949 seconds for 22 instances\n",
      "new order calculation took 0.3034243583679199 seconds for 23 instances\n",
      "new order calculation took 0.28252220153808594 seconds for 24 instances\n",
      "new order calculation took 0.24450278282165527 seconds for 25 instances\n"
     ]
    }
   ],
   "source": [
    "# find parameters for different configuration\n",
    "\n",
    "# TODO: do something about instance count of zero\n",
    "\n",
    "for inst_count in range(1, model_config['max_container_count']+1):\n",
    "    # add instance count to config\n",
    "    model_config.update({\n",
    "        'instance_count': inst_count,\n",
    "    })\n",
    "\n",
    "    # update the config\n",
    "    update_config(model_config)\n",
    "\n",
    "    # calculate and show Q\n",
    "    Q = single_model.get_single_container_q(single_coder, config=model_config)\n",
    "    # display(pd.DataFrame(Q))\n",
    "\n",
    "    req_count_prob = utility.solve_CTMC(Q)\n",
    "    req_df = pd.DataFrame(data = {\n",
    "        'req_count': [s[0] for s in single_coder.get_state_list()],\n",
    "        'req_count_prob': req_count_prob,\n",
    "    })\n",
    "\n",
    "    # calculate measure concurrency distribution\n",
    "    avg_count = model_config['stable_conc_avg_count']\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    req_count_averaged_vals, req_count_averaged_probs = utility.get_averaged_distribution(vals=req_df['req_count'], probs=req_df['req_count_prob'], avg_count=avg_count)\n",
    "    print(f\"new order calculation took {time.time() - start_time} seconds for {inst_count} instances\")\n",
    "\n",
    "    # calculate probability of different ordered instance count\n",
    "    new_order_val, new_order_prob = general_model.get_new_order_dist(req_count_averaged_vals, req_count_averaged_probs, model_config)\n",
    "\n",
    "    # plot the result\n",
    "    # plt.figure(figsize=(8,4))\n",
    "    # plt.bar(new_order_val, new_order_prob, width=1)"
   ]
  }
 ]
}