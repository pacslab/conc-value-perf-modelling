{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Building The General Model\n",
    "\n",
    "Using the analysis created by the previous sections, we will try to build and solve the\n",
    "general model for concurrency value autoscaling.\n",
    "\n",
    "\n",
    "One important thing to note here is that the general model is evaluated every 2 seconds\n",
    "because of the inherent autoscaling evaluation period of 2 seconds in knative. As a result\n",
    "we need to convert the rates of provisioning and deprovisioning of containers from\n",
    "time rates into probability rates (from CTMC to DTCM parameters)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# imports\n",
    "\n",
    "# important libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import scipy as sp\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# for better printing of variables\n",
    "from IPython.display import display\n",
    "\n",
    "# custom imports\n",
    "from concperf import single_model, general_model\n",
    "from concperf import utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update configuration dictionary for each instance count\n",
    "def update_config(config):\n",
    "    config['arrival_rate_server'] = config['arrival_rate_total'] / config['instance_count']\n",
    "    config['base_service_time'] = config['base_service_time_ms'] / 1000\n",
    "\n",
    "model_config = {\n",
    "    # 'instance_count' should be added for each state\n",
    "    'max_conc': 10,\n",
    "    'arrival_rate_total': 5,\n",
    "    'alpha': 0.11,\n",
    "    'base_service_time_ms': 1154,\n",
    "    'max_container_count': 25,\n",
    "    'target_conc': 0.7, # assumes target utilization\n",
    "    'max_scale_up_rate': 1000, # from N to 1000*N at most\n",
    "    'max_scale_down_rate': 2, # from N to N/2 at most\n",
    "    'stable_conc_avg_count': 300, # number of times monitored concurrency will be averaged in stable mode\n",
    "}\n",
    "\n",
    "single_coder = single_model.StateCoder(config=model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_state_coder = general_model.StateCoder(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "ready_count = 3\n",
    "next_ready_counts = list(range(0,11))\n",
    "provision_rate_base = 1\n",
    "deprovision_rate_base = 2\n",
    "\n",
    "solution, Q = general_model.get_prov_trans_probs(ready_count, next_ready_counts, provision_rate_base, deprovision_rate_base, max_t=2)\n",
    "\n",
    "solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Calculation took 0.946993350982666 seconds for 1 instances\n",
      "Calculation took 1.1270065307617188 seconds for 2 instances\n",
      "Calculation took 0.8439991474151611 seconds for 3 instances\n",
      "Calculation took 0.7739770412445068 seconds for 4 instances\n",
      "Calculation took 0.5979371070861816 seconds for 5 instances\n",
      "Calculation took 0.5130293369293213 seconds for 6 instances\n",
      "Calculation took 0.4870004653930664 seconds for 7 instances\n",
      "Calculation took 0.44997525215148926 seconds for 8 instances\n",
      "Calculation took 0.40897274017333984 seconds for 9 instances\n",
      "Calculation took 0.4019949436187744 seconds for 10 instances\n",
      "Calculation took 0.36898183822631836 seconds for 11 instances\n",
      "Calculation took 0.35602855682373047 seconds for 12 instances\n",
      "Calculation took 0.3509998321533203 seconds for 13 instances\n",
      "Calculation took 0.3340277671813965 seconds for 14 instances\n",
      "Calculation took 0.31002211570739746 seconds for 15 instances\n",
      "Calculation took 0.32196784019470215 seconds for 16 instances\n",
      "Calculation took 0.29802870750427246 seconds for 17 instances\n",
      "Calculation took 0.2940213680267334 seconds for 18 instances\n",
      "Calculation took 0.298999547958374 seconds for 19 instances\n",
      "Calculation took 0.26899003982543945 seconds for 20 instances\n",
      "Calculation took 0.26900577545166016 seconds for 21 instances\n",
      "Calculation took 0.26299071311950684 seconds for 22 instances\n",
      "Calculation took 0.26897430419921875 seconds for 23 instances\n",
      "Calculation took 0.2590038776397705 seconds for 24 instances\n",
      "Calculation took 0.2619593143463135 seconds for 25 instances\n"
     ]
    }
   ],
   "source": [
    "# find parameters for different configuration\n",
    "\n",
    "# TODO: do something about instance count of zero\n",
    "\n",
    "for inst_count in range(1, model_config['max_container_count']+1):\n",
    "    # add instance count to config\n",
    "    model_config.update({\n",
    "        'instance_count': inst_count,\n",
    "    })\n",
    "\n",
    "    # update the config\n",
    "    update_config(model_config)\n",
    "\n",
    "    # calculate and show Q\n",
    "    Q = single_model.get_single_container_q(single_coder, config=model_config)\n",
    "    # display(pd.DataFrame(Q))\n",
    "\n",
    "    req_count_prob = utility.solve_CTMC(Q)\n",
    "    req_df = pd.DataFrame(data = {\n",
    "        'req_count': [s[0] for s in single_coder.get_state_list()],\n",
    "        'req_count_prob': req_count_prob,\n",
    "    })\n",
    "\n",
    "    # calculate measure concurrency distribution\n",
    "    avg_count = model_config['stable_conc_avg_count']\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    req_count_averaged_vals, req_count_averaged_probs = utility.get_averaged_distribution(vals=req_df['req_count'], probs=req_df['req_count_prob'], avg_count=avg_count)\n",
    "    print(f\"Calculation took {time.time() - start_time} seconds for {inst_count} instances\")\n",
    "\n",
    "    # calculate probability of different ordered instance count\n",
    "    new_order_val, new_order_prob = general_model.get_new_order_dist(req_count_averaged_vals, req_count_averaged_probs, model_config)\n",
    "\n",
    "    # plot the result\n",
    "    # plt.figure(figsize=(8,4))\n",
    "    # plt.bar(new_order_val, new_order_prob, width=1)"
   ]
  }
 ]
}